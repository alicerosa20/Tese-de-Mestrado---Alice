% #############################################################################
% Abstract Text
% !TEX root = ../main.tex
% #############################################################################
% reset acronyms
\acresetall
% use \noindent in firts paragraph
\noindent In recent years, deep learning methods have been extensively studied for the segmentation of microscopy images to efficiently and accurately quantify and characterize cells, nuclei, and other biological structures, as this information is essential for the diagnosis of diseases, for example.

In this work, we address the segmentation of cell nuclei and Golgi in \ac{3D} fluorescence microscopy images as an unpaired image-to-image translation problem. For this task, we proposed the use of the CycleGAN model, which can be used as an unsupervised end-to-end framework. With this model, we are able to significantly reduce the training and testing time since it does not require manually labeled segmentation masks for training, but instead trains with synthetic masks.

Furthermore, the detection of nucleus-Golgi pairs is also important for the study of blood vessel formation. Therefore, the proposed segmentation model is extended to classify a third class, nucleus-Golgi pairs.

The experimental results obtained with the proposed CycleGAN model are compared with two well-known supervised segmentation models, \ac{3D} U-Net and Vox2Vox. The CycleGAN model led to the following results: Dice coefficient of 76.64\% for the nuclei class, 64.27\% for the Golgi class and 69.99\% for the nucleus-Golgi pairs class, with a difference of only 1.11\%, 5.11\% and 6.02\%, respectively, from the best results obtained with the supervised model \ac{3D} U-Net. Moreover, the time required to train and test the U-Net model is about 5.78 times longer than the time required to train and test the CycleGAN model.