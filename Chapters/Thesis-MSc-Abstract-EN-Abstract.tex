% #############################################################################
% Abstract Text
% !TEX root = ../main.tex
% #############################################################################
% reset acronyms
\acresetall
% use \noindent in firts paragraph
\noindent In recent years, Deep Learning methods have been intensively studied for segmenting fluorescence microscopy images to efficiently and accurately quantify and characterize cells, nuclei, or other biological structures for diagnosis of diseases, for example. 

In this work, we address the unsupervised end-to-end segmentation of cell nuclei and Golgi. We use the recently proposed CycleGAN model for the task of unpaired image-to-image translation between \ac{3D} fluorescence microscopy images and randomly synthesized masks. With this model, we are able to significantly reduce the time required to train and test the segmentation network because this model does not require manually labeled segmentation masks for training. 
%We also obtain a more transferable model that better learns the actual distribution of the data. 

Furthermore, the detection of nucleus-Golgi pairs is also important in the analysis of microscopic images for diagnosis. Therefore, the proposed segmentation network is extended to classify a third class, namely nucleus-Golgi pairs. 

The experimental results obtained with the proposed CycleGAN model are compared with two implemented well-known supervised segmentation models, \ac{3D} U-Net and Vox2Vox. The CycleGAN model lead to the following results: Dice Coefficient of 76,64\% for the nuclei class, 64,27\% for the Golgi class and 69,99\% for the nucleus-Golgi pairs class, with a difference of only 1,11\%, 5,11\% and 6,02\%, respectively, from the best results obtained with the supervised model \ac{3D} U-Net. Moreover, the time required to train and test the U-Net model is about 2,63 times longer than the time required to train and test the CycleGAN model.
